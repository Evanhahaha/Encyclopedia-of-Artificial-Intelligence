GAN 在图像生成上取得了巨大的成功，这无疑取决于 GAN 在博弈下不断提高建模能力，最终实现以假乱真的图像生成。

GAN 自 2014 年诞生至今也有 4 个多年头了，大量围绕 GAN 展开的文章被发表在各大期刊和会议，以改进和分析 GAN 的数学研究、提高 GAN 的生成质量研究、GAN 在图像生成上的应用（指定图像合成、文本到图像，图像到图像、视频）以及 GAN 在 NLP 和其它领域的应用。图像生成是研究最多的，并且该领域的研究已经证明了在图像合成中使用 GAN 的巨大潜力。

本文围绕 ***An Introduction to Image Synthesis with Generative Adversarial Nets*** 一文对 GAN 在图像生成应用做个综述。

# 论文引入

著名的物理学家 Richard Feynman 说过：*“What I cannot create, I do not understand”（对于我创造不出的事物，我是无法理解它的）*。我们现阶段接触到的 AI 产品，都是在尝试去看懂人类可以看懂的，例如对 ImageNet 的图像分类、AlphaGo、智能对话机器人等。

然而，我们仍然不能断定这些算法具有真正的“智能”，因为知道如何做某事并不一定意味着理解某些东西，而且真正智能的机器人理解其任务是至关重要的。

如果机器可以去 create，这也就可以说明机器对它的输入数据已经可以自主的建模，这是否可以说明机器在朝着更加“智慧”迈进了一步。这种 create 在机器学习的领域下，目前最为可行的方法是生成模型。通过学习的生成模型，机器甚至可以绘制不在训练集中但遵循相同分布的样本。

在生成模型中比较有影响力的有 ***VAE*** 、***PixelCNN*** 、***Glow*** 、***GAN*** 。其中在 2014 年提出的 GAN 可谓是生成模型中最受欢迎的，即使不能说 GAN 是一骑绝尘但也可谓是鹤立鸡群。

GAN 由两个神经网络组成，一个生成器和一个判别器组成，其中生成器试图产生欺骗判别器的真实样本，而判别器试图区分真实样本和生成样本。这种对抗博弈下使得生成器和判别器不断提高性能，在达到纳什平衡后生成器可以实现以假乱真的输出。

但是这种纳什平衡只存在于理论中，实际 GAN 的训练伴随着一些问题的限制。一个是 GAN 训练不稳定性另一个是模式崩溃。

GAN 存在的问题并没有限制 GAN 的发展，不断改进 GAN 的文章层出不穷，在这几年的铺垫下 GAN 已经发展得蛮成熟的。从这几年关于 GAN 的高质量文章可以看出，18 年以后的文章更多关注的是 GAN 在各个领域的应用，而之前的文章则是集中在 GAN 存在问题的改进。

GAN 在图像生成应用最为突出，当然在计算机视觉中还有许多其他应用，如图像绘画，图像标注，物体检测和语义分割。在自然语言处理中应用 GAN 的研究也是一种增长趋势，如文本建模，对话生成，问答和机器翻译。然而，在 NLP 任务中训练 GAN 更加困难并且需要更多技术，这也使其成为具有挑战性但有趣的研究领域。

***An Introduction to Image Synthesis with Generative Adversarial Nets\*** 一文是**概述 GAN 图像生成中使用的方法，并指出已有方法的优缺点**。本文则是对这篇论文进行个人的理解和翻译，并对其中的一些方法结合个人实际应用经验进行分析。

# GAN的基础

接触过 GAN 的学者如果对 GAN 的结构已经很熟悉，这一部分可以自行跳过。我们看一下 **GAN 的基础结构：**

![img](https://pic2.zhimg.com/80/v2-53383fc5a1344b890850cab4abfa588a_1440w.jpg)

GAN 可以将任意的分布作为输入，这里的 Z 就是输入，在实验中我们多取Z∼N(0,1)，也多取 [−1,1] 的均匀分布作为输入。生成器 G 的参数为 θ，输入 Z 在生成器下得到 G(z;θ)，输出可以被视为从分布中抽取的样本 G(z;θ)∼Pg。

对于训练样本 x 的数据分布为 Pdata，生成模型 G 的训练目标是使 Pg 近似Pdata。判别器 D 便是为了区分生成样本和真实样本的真假，训练发生器和判别器通过最小 - 最大游戏，其中**发生器 G 试图产生逼真的数据以欺骗判别器，而判别器 D 试图区分真实数据和合成数据**。这种博弈可公式化为：
$$
\min_G \max_D V(D,G) = E_{x \sim p_{data}(x)}[logD(x)]+E_{z\sim p_z(z)}[log(1-D(G(Z)))]
$$
最初的 GAN 使用完全连接的层作为其构建块。后来，***DCGAN*** 提出使用卷积神经网络实现了更好的性能，从那以后卷积层成为许多 GAN 模型的核心组件。

然而，当判别器训练得比发生器好得多时，D 可以有信心地从 G 中拒绝来自 G 的样本，因此损失项 log(1−D(G(z))) 饱和并且 G 无法从中学到任何东西。

为了防止这种情况，可以训练 G 来最大化 logD(G(z))，而不是训练 G 来最小化 log(1−D(G(z)))。虽然 G 的改变后的损失函数给出了与原始梯度不同的梯度，但它仍然提供相同的梯度方向并且不会饱和。

# 条件GAN

在原始 GAN 中，无法控制要生成的内容，因为输出仅依赖于随机噪声。我们可以将条件输入 c 添加到随机噪声 Z，以便生成的图像由 G(c,z) 定义。这就是 ***CGAN*** ，通常条件输入矢量 c 与噪声矢量 z 直接连接即可，并且将得到的矢量原样作为发生器的输入，就像它在原始 GAN 中一样。条件 c 可以是图像的类，对象的属性或嵌入想要生成的图像的文本描述，甚至是图片。

# 辅助分类器GAN (ACGAN)

为了提供更多的辅助信息并允许半监督学习，可以向判别器添加额外的辅助分类器，以便在原始任务以及附加任务上优化模型。这种方法的体系结构如下图所示，其中 C 是辅助分类器。

添加辅助分类器允许我们使用预先训练的模型（例如，在 ImageNet 上训练的图像分类器），并且在 ***ACGAN\*** 中的实验证明这种方法可以帮助生成更清晰的图像以及减轻模式崩溃问题。使用辅助分类器还可以应用在文本到图像合成和图像到图像的转换。































