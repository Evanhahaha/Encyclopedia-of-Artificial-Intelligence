# 统计学习
## 统计学习的特点
1. 统计学ai以计算机及网络为平台，是建立在计 
算机及网络之上的
2. 统计学习以数据为研究对象，是数据驱动的学科
3. 统计学习的目的是对数据进行预测与分析
4. 统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析
5. 统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论.
## 统计学习的对象
统计学习的对象是数据。它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。这里的同类数据是指具有某种共同性质的数据。
## 统计学习的方法
统计学习的方法是基于数据构建统计模型从而对数据进行预测与分析，统计学习由监督学习、非监督学习、半监督学习和强化学习等组成。  
我们主要讨论监督学习，这种情况下统计学习的方法可以概括如下：从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间；应用某个评价准则，从假设空间种选取一个最优的模型，使它对已知的数据及未知的测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，称其为统计学习方法的三要素，模型、策略和算法
# 监督学习 supervised learning
## 基本概念
- 输入空间、特征空间、输出空间
在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间（input space）与输出空间（output space）。
每个具体的输入是一个实例（instance），通常由特征向量（feature vector）表示，所有的特征向量存在的空间称为特征空间（feature space）。
- 联合概率分布
监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)。P(X,Y)表示分布函数，或分布密度函数。
- 假设空间
监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。
换句话说，学习的目的就在于找到最好的这样的模型。
模型属于由输入空间到输出空间的映射的集合。这个集合就是假设空间（hypothesis space）。
# 统计学习的三要素
## 模型
模型的假设空间（hypothesis space）包含所有可能的条件概率分布或决策函数。
假设空间可以用$\mathcal{F}$表示，可以定义为决策函数的集合,称为非概率模型。  
$$
\mathcal{F} = \{f|Y=f(X)\}
$$
其中，$X$和$Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$的变量，这时$\mathcal{F}$通常是由一个参数向量决定的函数族：
$$
\mathcal{F} = \{f|Y=f_\theta(X),\theta \in R^2\}
$$
参数向量$\theta$取值于n维欧氏空间$R^n$，称为参数空间(parameter space)
## 策略
1. 损失函数和风险函数


监督学习问题是在假设空间下中选取模型$\mathcal{F}$作为决策函数，对于给定的输入$X$,由$f(X)$给出相应的输出$Y$，这个输出的预测值$f(X)$与真实值$Y$可能一致也可能不一致，用一个损失函数（loss function）或代价函数（cost function）来度量 预测错误的程度．损失函数是$f(X)$和$Y$的非负实值函数，记作$L(Y,f(X))$. 统计学习常用的损失函数有以下几种： 
- 0-1损失函数(0-1 loss function)
$$L(Y,f(x))=\begin{cases}
1 & Y\neqf(X) \\
0 & z=0
\end{cases}$$
- 平方损失函数(quadratic loss function)
$$L(Y,f(x))=\begin{cases}
1 & z \\
0 & z>0
\end{cases}$$

- 绝对损失函数(absolute loss function)


- 对数损失函数(logarithmic loss function)


2. 经验风险最小化与结构风险最小化


