训练，验证，测试集

## 概括

- 训练集相当于上课学知识
- 验证集相当于课后的的练习题，用来纠正和强化学到的知识
- 测试集相当于期末考试，用来最终评估学习效果

## 细谈

**训练集**

训练集（Training Dataset）是用来训练模型使用的

**验证集**

当我们的模型训练好之后，我们并不知道他的表现如何。这个时候就可以使用验证集（Validation Dataset）来看看模型在新数据（验证集和测试集是不同的数据）上的表现如何。**同时通过调整超参数，让模型处于最好的状态**

验证集有2个主要的作用：

1. 评估模型效果，为了调整超参数而服务
2. 调整超参数，使得模型在验证集上的效果最好

说明：

1. 验证集不像训练集和测试集，它是非必需的。如果不需要调整超参数，就可以不使用验证集，直接用测试集来评估效果。
2. 验证集评估出来的效果并非模型的最终效果，主要是用来调整超参数的，模型最终效果以测试集的评估结果为准。

**测试集**

通过测试集的评估，我们会得到一些最终的评估指标，例如：准确率、精确率、召回率、F1等。

## 划分数据集

**交叉验证法**

3种主流的交叉验证法：

留出法，留一法，k折交叉验证

**留出法**

按照固定比例将数据集**静态的**划分为训练集、验证集、测试集。的方式就是留出法

1. 对于小规模样本集（几万量级），常用的分配比例是 60% 训练集、20% 验证集、20% 测试集。
2. 对于大规模样本集（百万级以上），只要验证集和测试集的数量足够即可，例如有 100w 条数据，那么留 1w 验证集，1w 测试集即可。1000w 的数据，同样留 1w 验证集和 1w 测试集。
3. 超参数越少，或者超参数很容易调整，那么可以减少验证集的比例，更多的分配给训练集。

**留一法**

每次的测试集都只有一个样本，要进行 m 次训练和预测。 这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。但是训练复杂度增加了，因为模型的数量与原始数据样本数量相同。 一般在数据缺乏时使用。

**k折交叉验证**

静态的「留出法」对数据的划分方式比较敏感，有可能不同的划分方式得到了不同的模型。「k 折交叉验证」是一种动态验证的方式，这种方式可以降低数据划分带来的影响。具体步骤如下：

1. 将数据集分为训练集和测试集，将测试集放在一边
2. 将训练集分为 k 份
3. 每次使用 k 份中的 1 份作为验证集，其他全部作为训练集。
4. 通过 k 次训练后，我们得到了 k 个不同的模型。
5. 评估 k 个模型的效果，从中挑选效果最好的超参数
6. 使用最优的超参数，然后将 k 份数据全部作为训练集重新训练模型，得到最终模型。

**k 一般取 10** 数据量小的时候，k 可以设大一点，这样训练集占整体比例就比较大，不过同时训练的模型个数也增多。 数据量大的时候，k 可以设小一点。

# 偏差、方差、噪声

在机器学习中，我们用训练数据集去训练一个模型，通常的做法是定义一个误差函数，通过将这个误差的最小化过程，来提高模型的性能。然而我们学习一个模型的目的是为了解决训练数据集这个领域中的一般化问题，单纯地将训练数据集的损失最小化，并不能保证在解决更一般的问题时模型仍然是最优，甚至不能保证模型是可用的。这个训练数据集的损失与一般化的数据集的损失之间的差异就叫做**泛化误差（generalization error）**。

而泛化误差可以分解为**偏差（Biase）**、**方差（Variance）**和**噪声（Noise）**。

Bias和Variance分别从两个方面来描述我们学习到的模型与真实模型之间的差距。

**Bias**是用**所有可能的训练数据集**训练出的**所有模型**的输出的**平均值**与**真实模型**的输出值之间的差异。

**Variance**是**不同的训练数据集训练出的模型**输出值之间的差异。

**噪声**的存在是学习算法所无法解决的问题，数据的质量决定了学习的上限。假设在数据已经给定的情况下，此时上限已定，我们要做的就是尽可能的接近这个上限。

| 符号            | 含义                              |
| --------------- | --------------------------------- |
| $x$             | 测试样本                          |
| $D$             | 数据集                            |
| $y_D$           | x在数据集中的标记                 |
| $y$             | x的真实标记                       |
| $f$             | 训练集D学得的模型                 |
| $f(x;D)$        | 由训练集D学得的模型f对x的预测输出 |
| \overline{f}(x) | 模型f对x的期望预测输出            |

以回归任务为例，学习算法的期望预测为：
$$
\overline{f}(x)=E_D[f(x;D)]
$$
这里的期望预测也就是针对不同数据集D，模型f对样本x的预测值取其期望，也叫做**平均预测（average predicted）。**

**（1）方差定义：**

使用样本数相同的不同训练集产生的**方差**为：
$$
var(x)=E_D[(f(x;D)-\overline{f}(x))^2]
$$
**方差的含义：方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。**

**（2）偏差定义：**

期望输出与真实标记的差别称为**偏差（bias）**，即：
$$
bias^2(x)=(\overline{f}(x)-y)^2
$$
**偏差的含义：偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。**

**（3）噪声：**

噪声为：
$$
\xi ^2 = E_D [(y_D-y)^2]
$$
**噪声的含义：噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。**

![BiasVariance](../img/DL/BiasVariance.jpg)



初始模型训练完成后，我首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么你要做的就是选择一个新的网络，比如含有更多隐藏层或者隐藏单元的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法，但是可能有用，也可能没用。

训练学习算法时，会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到可以拟合数据为止，至少能够拟合训练集。

如果网络足够大，通常可以很好的拟合训练集，**只要你能扩大网络规模**，如果图片很模糊，算法可能无法拟合该图片，但如果有人可以分辨出图片，如果你觉得基本误差不是很高，那么训练一个更大的网络，你就应该可以……至少可以很好地拟合训练集，至少可以拟合或者过拟合训练集。一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，我们要**查看验证集性能**，我们能从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是采用更多数据，如果你能做到，会有一定的帮助，但有时候，我们无法获得更多数据，我们也可以尝试通过正则化来减少过拟合。

**两个关键点**

第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同，通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。举个例子，**如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不是更有效的方法**，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这一点有助于我们选择出最有效的方法。

第二点，在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我们能尝试的方法有很多。可以增加偏差，减少方差，也可以减少偏差，增加方差，但是在深度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差却不影响到另一方。但在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据，那么也并非只有这两种情况，我们假定是这样，那么，只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。我觉得这就是深度学习对监督式学习大有裨益的一个重要原因，也是我们不用太过关注如何平衡偏差和方差的一个重要原因，但有时我们有很多选择，减少偏差或方差而不增加另一方。最终，我们会得到一个非常规范化的网络。

# 正则化

## 出现原因

深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。

首先，从使用正则化的目的角度：**正则化是为了防止过拟合**

<img src="../img/DL/overfit.jpg" alt="Overfitting" style="zoom:80%;" />

## 二次正则项

线性的损失函数
$$
E(w)=\frac{1}{2}\sum_{n=1}^N\{t_n-w^T\phi(X_n)\}^2
$$


$E(w)$是**损失函数（又称误差函数 or 评价函数）**，E即Evaluate，有时候写成L即Loss
$t_n$是测试集的真实输出，又称目标变量【对应第一幅图中的蓝色点】
$w$ 是权重（需要训练的部分，未知数）

$\phi()$是**基函数**，例如多项式函数，核函数
测试样本有n个数据
整个函数直观解释就是**误差平方和**，$\frac{1}{2}$只是为了**求导后消去方便计算**

加**正则化项**，得到最终的**误差函数（Error function）**
$$
\frac{1}{2}\sum_{n=1}^N\{t_n-w^T\phi(X_n)\}^2+\frac{\lambda}{2}w^Tw
$$
目标函数 = 误差函数（损失函数 or 评价函数） + 正则化项
$\lambda$被称为正则化系数，**越大，这个限制越强**

对$w$求导，并令为0，可以解得：
$$
w=(\lambda I+\phi	^T\phi)^{-1}\phi	^Tt
$$

## 一般正则项

$$
\frac{1}{2}\sum_{n=1}^N\{t_n-w^T\phi(X_n)\}^2+\frac{\lambda}{2}\sum_{j=1}^M|w_j|^q
$$

> M是模型的阶次（表现形式是数据的维度），比如M=2，就是一个平面（二维）内的点





































