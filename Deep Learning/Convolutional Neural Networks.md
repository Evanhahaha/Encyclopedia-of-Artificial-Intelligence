# 卷积神经网络基础

## 计算机视觉介绍

计算机视觉是一个飞速发展的一个领域，这多亏了深度学习。深度学习与计算机视觉可以帮助汽车，查明周围的行人和汽车，并帮助汽车避开它们。还使得人脸识别技术变得更加效率和精准，你们即将能够体验到或早已体验过仅仅通过刷脸就能解锁手机或者门锁。当你解锁了手机，我猜手机上一定有很多分享图片的应用。在上面，你能看到美食，酒店或美丽风景的图片。有些公司在这些应用上使用了深度学习技术来向你展示最为生动美丽以及与你最为相关的图片。机器学习甚至还催生了新的艺术类型。

第一，计算机视觉的高速发展标志着新型应用产生的可能，这是几年前，人们所不敢想象的。通过学习使用这些工具，你也许能够创造出新的产品和应用。

其次，即使到头来你未能在计算机视觉上有所建树，但我发现，人们对于计算机视觉的研究是如此富有想象力和创造力，由此衍生出新的神经网络结构与算法，这实际上启发人们去创造出计算机视觉与其他领域的交叉成果。

## 边缘检测

卷积运算是卷积神经网络最基本的组成部分，使用边缘检测作为入门样例。

<img src="../img/DL/Edgedetection.png" alt="Edgedetection" style="zoom:80%;" />

在这张图片中的栏杆就对应垂直线，与此同时，这些行人的轮廓线某种程度上也是垂线，这些线是垂直边缘检测器的输出。同样，你可能也想检测水平边缘，比如说这些栏杆就是很明显的水平线，它们也能被检测到。

<img src="../img/DL/VerticalEdge.png" alt="VerticalEdge" style="zoom:80%;" />

## Padding

为了构建深度神经网络，你需要学会使用的一个基本的卷积操作就是**padding**，让我们来看看它是如何工作的。

<img src="../img/DL/Padding.png" alt="Padding" style="zoom:80%;" />

如果你用一个3×3的过滤器卷积一个6×6的图像，你最后会得到一个4×4的输出，也就是一个4×4矩阵。那是因为你的3×3过滤器在6×6矩阵中，只可能有4×4种可能的位置。这背后的数学解释是，如果我们有一个$ n \times n$的图像，用$f \times f$的过滤器做卷积，那么输出的维度就是$(n-f+1)\times (n-f+1)$。在这个例子里是4，因此得到了一个4×4的输出。

这样的话会有两个缺点，**第一个缺点是每次做卷积操作，你的图像就会缩小**，从6×6缩小到4×4，你可能做了几次之后，你的图像就会变得很小了，可能会缩小到只有1×1的大小。你可不想让你的图像在每次识别边缘或其他特征时都缩小，这就是第一个缺点。

第二个缺点时，如果你注意角落边缘的像素，这个像素点（绿色阴影标记）只被一个输出所触碰或者使用，因为它位于这个3×3的区域的一角。但如果是在中间的像素点，比如这个（红色方框标记），就会有许多3×3的区域与之重叠。**所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。**

为了解决这些问题，你可以在卷积操作之前填充这幅图像。在这个案例中，你可以沿着图像边缘再填充一层像素。如果你这样操作了，那么6×6的图像就被你填充成了一个8×8的图像。如果你用3×3的图像对这个8×8的图像卷积，你得到的输出就不是4×4的，而是6×6的图像，你就得到了一个尺寸和原始图像6×6的图像。

习惯上，你可以用0去填充，如果$p$是填充的数量，在这个案例中，$p=1$，因为我们在周围都填充了一个像素点，输出也就变成了$(n+2p-f+1)\times (n+2p-f+1)$，所以就变成了$6 \times 6$，和输入的图像一样大。这样一来，丢失信息或者更准确来说角落或图像边缘的信息发挥的作用较小的这一缺点就被削弱了。如果你想的话，也可以填充两个像素点，也就是说在这里填充一层。实际上你还可以填充更多像素。

至于选择填充多少像素，通常有两个选择，分别叫做**Valid**卷积和**Same**卷积。

**Valid**卷积意味着不填充，这样的话，如果你有一个$n \times n$的图像，用一个$f \times f$的过滤器卷积，它将会给你一个$(n-f+1)\times (n-f+1)$维的输出。这类似于我们在前面的视频中展示的例子，有一个6×6的图像，通过一个3×3的过滤器，得到一个4×4的输出。

另一个经常被用到的填充方法叫做**Same**卷积，那意味你填充后，你的输出大小和输入大小是一样的。根据这个公式$n-f+1$，当你填充$p$个像素点，$n$就变成了$n+2p$，最后公式变为$n+2p-f+1$。因此如果你有一个$n \times n$的图像，用个像素填充边缘，输出的大小就是这样的$(n+2p-f+1)\times (n+2p-f+1)$。

<img src="../img/DL/Padding.gif" alt="Padding" style="zoom:80%;" />

## 卷积步长（Strided convolutions）

卷积中的步幅是另一个构建卷积神经网络的基本操作。

滑动卷积核时，我们会先从输入的左上角开始，每次往左滑动一列或者往下滑动一行逐一计算输出，我们将每次滑动的行数和列数称为Stride，在之前的图片中，Stride=1；在下图中，Stride=2。

<img src="../img/DL/Stride.gif" alt="Stide" style="zoom:80%;" />

卷积过程中，有时需要通过padding来避免信息损失，有时也要在卷积时通过设置的**步长（Stride）**来压缩一部分信息，或者使输出的尺寸小于输入的尺寸。

**Stride的作用：**是成倍缩小尺寸，而这个参数的值就是缩小的具体倍数，比如步幅为2，输出就是输入的1/2；步幅为3，输出就是输入的1/3。以此类推。

**【卷积核的大小一般为奇数\*奇数】** 1*1，3*3，5*5，7*7都是最常见的。**这是为什么呢？**为什么没有偶数*偶数？

**（1）更容易padding**

在卷积时，我们有时候需要卷积前后的尺寸不变。这时候我们就需要用到padding。假设图像的大小，也就是被卷积对象的大小为n*n，卷积核大小为k*k，padding的幅度设为(k-1)/2时，卷积后的输出就为(n-k+2*((k-1)/2))/1+1=n，即卷积输出为n*n，保证了卷积前后尺寸不变。但是如果k是偶数的话，(k-1)/2就不是整数了。

**（2）更容易找到卷积锚点**

在CNN中，进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。若卷积核为奇数，卷积锚点很好找，自然就是卷积模块中心，但如果卷积核是偶数，这时候就没有办法确定了，让谁是锚点似乎都不怎么好。

**【卷积的计算公式】**

**输入图片的尺寸：**一般用 ![[公式]](https://www.zhihu.com/equation?tex=n%5Ctimes+n) 表示输入的image大小。

**卷积核的大小：**一般用 ![[公式]](https://www.zhihu.com/equation?tex=f%5Ctimes+f) 表示卷积核的大小。

**填充（Padding）：**一般用 ![[公式]](https://www.zhihu.com/equation?tex=p) 来表示填充大小。

**步长(Stride)：**一般用 ![[公式]](https://www.zhihu.com/equation?tex=s) 来表示步长大小。

**输出图片的尺寸：**一般用 ![[公式]](https://www.zhihu.com/equation?tex=o) 来表示。

如果已知 ![[公式]](https://www.zhihu.com/equation?tex=n) 、 ![[公式]](https://www.zhihu.com/equation?tex=f) 、 ![[公式]](https://www.zhihu.com/equation?tex=p) 、 ![[公式]](https://www.zhihu.com/equation?tex=s) 可以求得 ![[公式]](https://www.zhihu.com/equation?tex=o) ，**计算公式如下：**![[公式]](https://www.zhihu.com/equation?tex=o%3D%5Clfloor+%5Cfrac%7Bn+%2B+2p+-+f%7D%7Bs%7D++%5Crfloor+%2B+1)

其中"![[公式]](https://www.zhihu.com/equation?tex=%5Clfloor+%5C+%5Crfloor)"是向下取整符号，用于结果不是整数时进行向下取整。

## 三维卷积

上述例子都只包含一个输入通道。实际上，大多数输入图像都有 RGB 3个通道。

![img](https://pic1.zhimg.com/80/v2-fc70463d7f82f7268ee23b7235515f4a_1440w.jpg)

这里就要涉及到“卷积核”和“filter”这两个术语的区别。在只有一个通道的情况下，“卷积核”就相当于“filter”，这两个概念是可以互换的。但在一般情况下，它们是两个完全不同的概念。**每个“filter”实际上恰好是“卷积核”的一个集合**，在当前层，每个通道都对应一个卷积核，且这个卷积核是独一无二的。

**多通道卷积的计算过程：**将矩阵与滤波器对应的每一个通道进行卷积运算，最后相加，形成一个单通道输出，加上偏置项后，我们得到了一个最终的单通道输出。如果存在多个filter，这时我们可以把这些最终的单通道输出组合成一个总输出。

这里我们还需要**注意**一些问题——滤波器的通道数、输出特征图的通道数。

**某一层滤波器的通道数 = 上一层特征图的通道数。**如上图所示，我们输入一张 ![[公式]](https://www.zhihu.com/equation?tex=6%5Ctimes6%5Ctimes3) 的RGB图片，那么滤波器（ ![[公式]](https://www.zhihu.com/equation?tex=3%5Ctimes3%5Ctimes3) ）也要有三个通道。

**某一层输出特征图的通道数 = 当前层滤波器的个数。**如上图所示，当只有一个filter时，输出特征图（ ![[公式]](https://www.zhihu.com/equation?tex=4%5Ctimes4) ）的通道数为1；当有2个filter时，输出特征图（![[公式]](https://www.zhihu.com/equation?tex=4%5Ctimes4%5Ctimes2) ）的通道数为2。



如果要计算下一个输出，你把这个立方体滑动一个单位，再与这27个数相乘，把它们都加起来，就得到了下一个输出，以此类推。

<img src="../img/DL/3DConvolution.png" alt="3DConvolution" style="zoom:80%;" />

那么，这个能干什么呢？举个例子，这个过滤器是3×3×3的，如果你想检测图像红色通道的边缘，那么你可以将第一个过滤器设为$ \left[
 \begin{matrix}
   1 & 0 & -1 \\
   1 & 0 & -1 \\
   1 & 0 & -1
  \end{matrix}
  \right] $，和之前一样，而绿色通道全为0， \left[
 \begin{matrix}
   0 & 0 & 0 \\
   0 & 0 & 0 \\
   0 & 0 & 0
  \end{matrix}
  \right] ，蓝色也全为0。如果你把这三个堆叠在一起形成一个3×3×3的过滤器，那么这就是一个检测垂直边界的过滤器，但只对红色通道有用。

标准的卷积网络：

Convolution、Pooling、Fully connected

## 池化层

除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性，我们来看一下。

<img src="../img/DL/Maxpooling.png" alt="Maxpooling" style="zoom:80%;" />

先举一个池化层的例子，然后我们再讨论池化层的必要性。假如输入是一个4×4矩阵，用到的池化类型是最大池化（**max pooling**）。执行最大池化的树池是一个2×2矩阵。执行过程非常简单，把4×4的输入拆分成不同的区域，我把这个区域用不同颜色来标记。对于2×2的输出，输出的每个元素都是其对应颜色区域中的最大元素值。

你可以把这个4×4输入看作是某些特征的集合，也许不是。你可以把这个4×4区域看作是某些特征的集合，也就是神经网络中某一层的非激活值集合。数字大意味着可能探测到了某些特定的特征，左上象限具有的特征可能是一个垂直边缘，一只眼睛，或是大家害怕遇到的**CAP**特征。显然左上象限中存在这个特征，这个特征可能是一只猫眼探测器。然而，右上象限并不存在这个特征。最大化操作的功能就是只要在任何一个象限内提取到某个特征，它都会保留在最大化的池化输出里。所以最大化运算的实际作用就是，如果在过滤器中提取到某个特征，那么保留其最大值。如果没有提取到这个特征，可能在右上象限中不存在这个特征，那么其中的最大值也还是很小，这就是最大池化的直观理解。

<img src="../img/DL/AveragePooling.png" alt="AveragePooling" style="zoom:80%;" />

另外还有一种类型的池化，平均池化，它不太常用。目前来说，最大池化比平均池化更常用。但也有例外，就是深度很深的神经网络，你可以用平均池化来分解规模为7×7×1000的网络的表示层，在整个空间内求平均值，得到1×1×1000。

有几点要注意，第一，池化层和最大池化层没有参数；第二卷积层的参数相对较少其实许多参数都存在于神经网络的全连接层。观察可发现，随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。示例中，激活值尺寸在第一层为6000，然后减少到1600，慢慢减少到84，最后输出**softmax**结果。我们发现，许多卷积网络都具有这些属性，模式上也相似。









































